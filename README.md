# StyleGanJittor (Tsinghua university computer graphics course)
Jittor 64*64 implementation of StyleGAN (Tsinghua university computer graphics course)
This project is a repetition of StyleGAN based on python 3.8 + [计图（jittor）](https://github.com/Jittor/jittor) and [The open source StyleGAN-Pytorch project](https://github.com/rosinality/style-based-gan-pytorch). I train the model on the color_symbol_7k dataset for 40000 iterations. The model can generate 64×64 symbolic images.


StyleGAN is a generative adversarial network for image generation proposed by NVIDIA in 2018. According to the [paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html), the generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. The main improvement of this network model over previous models is the structure of the generator, including the addition of an eight-layer Mapping Network, the use of the AdaIn module, and the introduction of image randomness - these structures allow the generator to The overall features of the image are decoupled from the local features to synthesize images with better effects; at the same time, the network also has better latent space interpolation effects.

(Karras T, Laine S, Aila T. A style-based generator architecture for generative adversarial networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 4401-4410.)
